# DocVideoQA
## 项目简介​
DocVideoQA 项目专注于以文档为中心的视频问答任务（Document Video Question Answering，DocVideoQA），目标是推动机器对这类视频内容的深度理解。在远程工作与在线课程日益普及的当下，基于文档的教学视频数量激增，但由于缺乏适配的数据集，且任务本身存在复杂性，该领域的研究仍较为滞后。​
本项目开创性地引入 DocVideoQA 任务和数据集，并开发 DV-LLaMA 模型。通过多阶段训练与对比学习策略，增强模型对文档视频中视觉、音频特征的理解与整合能力，在相关任务上收获显著成效。​
## 核心创新点​
  定义新任务：首次提出 DocVideoQA 任务，填补以文档为中心的视频问答领域空白，将文档问答拓展至视频模态。​
  构建数据集：创建的数据集涵盖 1,454 个视频（23 个类别，总时长约 828 小时）与 154K 问答对，结合人工标注与 GPT 辅助生成，从多维度评估模型对视频内容的理解能力。​
  开发模型：设计 DV-LLaMA 多模态大语言模型，采用单分支特征增强训练、对比学习对齐训练和多模态融合问答训练的多阶段训练方法，有效提升模型对文档视频的理解性能。​
## 开源文件结构与功能说明​
### requirement.txt​
该文件罗列了运行项目所需的软件包及对应版本依赖，确保项目在正确环境下运行。使用以下命令安装依赖：​
​
pip install -r requirement.txt​
​
### data 文件夹​
  - download 文件夹：提供视频文件下载的相关说明或脚本，助力用户获取构建数据集所需的原始视频资源。​
  - generate_QA.py：用于依据视频内容生成问答对的 Python 脚本，融合人工标注逻辑与 GPT 辅助生成机制，按信息提取、内容理解和时间感知三类问题设计，为模型训练与评估提供数据支撑。​
  - dataset 文件夹：包含 test 和 dev 子文件夹，其中的 json 文件存储测试集与开发集的视频、问题及答案等数据，用于模型测试与调试。​
  - vid_to_mp3.py：从视频文件中提取音频内容，为后续音频处理与多模态融合奠定基础，是视频音频信息处理的关键环节。​
### code 文件夹​
  - Baseline 文件夹：存放 MiniGPT - 4、Video - ChatGPT、Video - LLaMA 等开源模型的相关代码或配置文件，作为对比基线，便于直观展现 DV-LLaMA 模型的优势。​
  - DV-LLaMA 文件夹​
  -   train.py：DV-LLaMA 模型的训练代码，实现多阶段训练流程，逐步优化模型对文档视频的理解能力。​
  -   utils.py：包含训练过程中的实用工具函数，如数据预处理、模型评估辅助函数等，为训练提供支持。​
  -   model 文件夹：存储 DV-LLaMA 模型的结构定义、参数文件等核心内容。​


本项目的 arXiv 地址：https://arxiv.org/abs/2503.15887，已收录于 ICASSP2025。使用过程中若有任何问题或建议，欢迎提交 Issue 交流，期待您基于本开源项目开展更深入的研究！​

